{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "pd.set_option('display.max_columns',5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission_Byiv0dS.csv\n",
      "test_QyjYwdj.csv\n",
      "--------------------\n",
      "campaign_data.csv\n",
      "coupon_item_mapping.csv\n",
      "customer_demographics.csv\n",
      "customer_transaction_data.csv\n",
      "item_data.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "#printing filenames\n",
    "for filename in os.listdir('./data/'):\n",
    "    if filename.endswith('.csv'):\n",
    "        print(filename)\n",
    "\n",
    "print('-'*20)\n",
    "\n",
    "for filename in os.listdir('./data/train_AUpWtIz/'):\n",
    "    if filename.endswith('.csv'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading files\n",
    "train = pd.read_csv('./data/train_AUpWtIz/train.csv')\n",
    "campaign = pd.read_csv('./data/train_AUpWtIz/campaign_data.csv')\n",
    "items = pd.read_csv('./data/train_AUpWtIz/item_data.csv')\n",
    "coupons = pd.read_csv('./data/train_AUpWtIz/coupon_item_mapping.csv')\n",
    "cust_demo = pd.read_csv('./data/train_AUpWtIz/customer_demographics.csv')\n",
    "cust_tran = pd.read_csv('./data/train_AUpWtIz/customer_transaction_data.csv')\n",
    "\n",
    "test = pd.read_csv('./data/test_QyjYwdj.csv')\n",
    "sample = pd.read_csv('./data/sample_submission_Byiv0dS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Campaign ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#todatetime\n",
    "campaign['start_date'] = pd.to_datetime(campaign['start_date'], format = '%d/%m/%y')\n",
    "campaign['end_date'] = pd.to_datetime(campaign['end_date'], format = '%d/%m/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding campaign type to train and test\n",
    "train['campaign_type'] = train.campaign_id.map(campaign.groupby('campaign_id').campaign_type.apply(lambda x: x.unique()[0]))\n",
    "test['campaign_type'] = test.campaign_id.map(campaign.groupby('campaign_id').campaign_type.apply(lambda x: x.unique()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Customer demographics ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type of family size, no of children = int64\n",
    "cust_demo['family_size'] = cust_demo.family_size.apply(lambda x: int(re.sub('\\+','',x)))\n",
    "cust_demo['no_of_children'] = cust_demo.no_of_children.apply(lambda x: float(re.sub('\\+','',x)) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling nans marital_status\n",
    "\n",
    "#customers with family size =1 will be single\n",
    "cust_demo.loc[pd.isnull(cust_demo.marital_status) & (cust_demo.family_size == 1),'marital_status'] = 'Single'\n",
    "\n",
    "#customers whos fam size - no of childrens == 1, will also be single\n",
    "cust_demo.loc[(cust_demo.family_size - cust_demo.no_of_children == 1) & pd.isnull(cust_demo.marital_status),'marital_status'] = 'Single'\n",
    "\n",
    "#from the orignal data we have 142 of 152 customers with diff of 2 in their fam size and #childrens are Married\n",
    "cust_demo.loc[(pd.isnull(cust_demo.marital_status)) & ((cust_demo.family_size - cust_demo.no_of_children) == 2)  & (pd.notnull(cust_demo.no_of_children)),'marital_status'] = 'Married'\n",
    "\n",
    "#original data shows customers with fam size == 2, and nans in no of childrens are majorly Married\n",
    "cust_demo.loc[pd.isnull(cust_demo.marital_status) & (pd.isnull(cust_demo.no_of_children)) & (cust_demo.family_size ==2),'marital_status'] = 'Married'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling nans in no of children\n",
    "\n",
    "#Married people with family_size ==2 will have 0 childrens\n",
    "cust_demo.loc[pd.isnull(cust_demo.no_of_children) & (cust_demo.marital_status == 'Married') & (cust_demo.family_size == 2),'no_of_children'] = 0.0\n",
    "\n",
    "#customers with family size 1 will have zero childrens\n",
    "cust_demo.loc[pd.isnull(cust_demo.no_of_children) & (cust_demo.family_size == 1), 'no_of_children'] = 0.0\n",
    "\n",
    "#singles with family size == 2, will probably have 1 child\n",
    "cust_demo.loc[pd.isnull(cust_demo.no_of_children) & (cust_demo.family_size == 2),'no_of_children'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################## Customer transactions ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust_tran['date'] = pd.to_datetime(cust_tran['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## common ########################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merging train test and cust_demo on campaign_id\n",
    "train = pd.merge(train,cust_demo, on='customer_id', how='left')\n",
    "test = pd.merge(test,cust_demo, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Intersection between Items bought by customer and items available in coupon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cust2items\n",
    "cust_tran['str_item'] = cust_tran.item_id.apply(lambda x: str(x)) #did this to calculate d_cust2items, no need further\n",
    "d_cust2items = cust_tran.groupby('customer_id').str_item.apply(lambda x: ' '.join(x)).to_dict()\n",
    "cust_tran.drop('str_item',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coupon2items\n",
    "d_coupon2items = coupons.groupby('coupon_id').item_id.apply(lambda x: ' '.join(list(x.apply(lambda x: str(x))))).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intersect of cust2items and coupon2items (increased score by 0.14)\n",
    "train['bought_X_vailable'] = train[['coupon_id','customer_id']].apply(lambda x : len(np.intersect1d(d_cust2items[x[1]].split() , d_coupon2items[x[0]].split())) , axis=1)\n",
    "test['bought_X_vailable'] = test[['coupon_id','customer_id']].apply(lambda x : len(np.intersect1d(d_cust2items[x[1]].split() , d_coupon2items[x[0]].split())) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item2coupons\n",
    "d_item2coupons = coupons.groupby('item_id').coupon_id.apply(lambda x: ' '.join(list(x.apply(lambda x: str(x))))).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adding col for whether coupon was applied on that item (i.e redeemed or not)\n",
    "cust_tran['redeem'] = cust_tran.coupon_discount.apply(lambda x: 1 if x<0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############  1.) Calculating redeemed % per item from cust_tran\n",
    "#               2.) Summing all those per for items in a coupon, take mean finally\n",
    "#               3.) map it to coupons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting dict for redeem perc per item from cust tran\n",
    "d_per_item_redeemed_history = ((cust_tran.groupby('item_id').redeem.sum() / cust_tran.groupby('item_id').redeem.count()) *100).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some items corresponding to test coupons are not in d_per_item_redeemed_hist hence need for this func\n",
    "def item_redeem_func(x):\n",
    "    for item in d_coupon2items[x].split():\n",
    "        per = []\n",
    "        try:\n",
    "            per.append(d_per_item_redeemed_history[int(item)])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    k = [np.mean(per) if pd.isna(np.mean(per)) == False else 0]\n",
    "    return k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#applying the above func to coupon_id\n",
    "train['item_redeem'] = train.coupon_id.apply(item_redeem_func)\n",
    "test['item_redeem'] = test.coupon_id.apply(item_redeem_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### redeem per acco to cust (same thing as above, but here wrt customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#how have customers taken the discount\n",
    "d_per_cust_redeem_history = ((cust_tran.groupby('customer_id').redeem.sum() / cust_tran.groupby('customer_id').redeem.count())*100).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a col for cust redeem #increased score by 0.03\n",
    "train['cust_redeem'] = train.customer_id.map(d_per_cust_redeem_history)\n",
    "test['cust_redeem'] = test.customer_id.map(d_per_cust_redeem_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding net price\n",
    "cust_tran['net_price'] = cust_tran['selling_price'] - cust_tran['other_discount'] - cust_tran['coupon_discount']\n",
    "\n",
    "#dict for cust_id to income bracket\n",
    "d_cust2_incomebrac = cust_demo[['customer_id','income_bracket']].set_index('customer_id').to_dict()['income_bracket']\n",
    "\n",
    "#adding income bracket col in customer trans\n",
    "cust_tran['income_bracket'] = cust_tran.customer_id.map(d_cust2_incomebrac)\n",
    "\n",
    "#merging cust_trans with items on item_id\n",
    "cust_tran = pd.merge(cust_tran, items, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### redeem history mapped to cust based on category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redeem history based on category\n",
    "d_per_cat_redeem_history = (cust_tran.groupby('category').redeem.sum() / cust_tran.groupby('category').redeem.count()*1000).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(increased score by 0.0001)\n",
    "d_per_cust_redeem_history_catwali = cust_tran.groupby('customer_id').category.apply(lambda x: np.mean([d_per_cat_redeem_history[k] for k in x.values]))\n",
    "\n",
    "train['cat_cust_redeem'] = train.customer_id.map(d_per_cust_redeem_history_catwali)\n",
    "test['cat_cust_redeem'] = test.customer_id.map(d_per_cust_redeem_history_catwali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ if for a customer brands bought by him are available in the coupon given, high chance of redeem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dict for all brands per customer\n",
    "d_cust2brands = cust_tran.groupby('customer_id').brand.apply(lambda x: ' '.join([str(k) for k in x.unique()])).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dict for item 2 brand\n",
    "d_item2brand = cust_tran.groupby('item_id').brand.apply(lambda x: x.unique()[0]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupons['brand'] = coupons.item_id.map(d_item2brand).fillna('99999999999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict for item 2 brand\n",
    "d_coupon2brands = coupons.groupby('coupon_id').brand.apply(lambda x: ' '.join([str(int(k)) for k in x.unique()])).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding col of intersection of cust2brand and item2brand\n",
    "train['brand_bot'] = train[['customer_id','coupon_id']].apply(lambda x: len(np.intersect1d(d_cust2brands[x[0]].split(), d_coupon2brands[x[1]].split())), axis=1)\n",
    "test['brand_bot'] = test[['customer_id','coupon_id']].apply(lambda x: len(np.intersect1d(d_cust2brands[x[0]].split(), d_coupon2brands[x[1]].split())), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Imputing rented and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling nans in train.rented with 2\n",
    "train.rented.fillna(2,inplace=True)\n",
    "test.rented.fillna(2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imputing age_range based on campaign_id\n",
    "\n",
    "def d_age(df):\n",
    "    k = df.groupby('campaign_id').age_range.value_counts()\n",
    "    k = k.reset_index(name='value').sort_values(['campaign_id','value'], ascending=[True,False])\n",
    "    d_age = {}\n",
    "    for i in list(df.campaign_id.unique()):\n",
    "        df = k.loc[k.campaign_id == i,['age_range','value']]\n",
    "        df = df.set_index('age_range')\n",
    "        max_val_per_campaign = df.idxmax().value\n",
    "        d_age[i] = max_val_per_campaign\n",
    "        \n",
    "    return d_age\n",
    "\n",
    "    \n",
    "#filling nans with d_age\n",
    "train.loc[(pd.isnull(train.age_range)),'age_range'] = train.loc[(pd.isnull(train.age_range)),'campaign_id'].map(d_age(train))\n",
    "test.loc[(pd.isnull(test.age_range)),'age_range'] = test.loc[(pd.isnull(test.age_range)),'campaign_id'].map(d_age(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping some cols\n",
    "#train.drop(['marital_status','family_size','no_of_children','income_bracket'],axis=1,inplace=True)\n",
    "#test.drop(['marital_status','family_size','no_of_children','income_bracket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding brand (most frequent)\n",
    "train['brand'] = train.coupon_id.map(coupons.groupby('coupon_id').brand.apply(lambda x: x.values[0]).to_dict())\n",
    "test['brand'] = test.coupon_id.map(coupons.groupby('coupon_id').brand.apply(lambda x: x.values[0]).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#col for whether cust and coup is in test or not ---> (in order to make val set)\n",
    "commom_cust = np.intersect1d(train.customer_id.unique(),test.customer_id.unique())\n",
    "commom_coup = np.intersect1d(train.coupon_id.unique(),test.coupon_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding col to see whether cust is in test or not \n",
    "train['test_cust'] = train.customer_id.apply(lambda x: 1 if x in commom_cust else 0)\n",
    "train['test_coup'] = train.coupon_id.apply(lambda x: 1 if x in commom_coup else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Validation set\n",
    "# val_index\n",
    "\n",
    "#(len(train[pd.isnull(train.family_size) & (train.redemption_status == 1)]) / len(train)) * 7837 #16\n",
    "index1 = train[pd.isnull(train.family_size) & (train.redemption_status == 1) & (train.test_cust == 1) & (train.test_coup == 1)].sample(16, random_state=1996).index\n",
    "\n",
    "#(len(train[pd.notnull(train.family_size) & (train.redemption_status == 1)]) / len(train) ) * 7837 #57\n",
    "index2 = train[pd.notnull(train.family_size) & (train.redemption_status == 1) & (train.test_cust == 1) & (train.test_coup == 1)].sample(57, random_state=1996).index\n",
    "\n",
    "#(len(train[pd.isnull(train.family_size) & (train.redemption_status == 0)]) / len(train)) * 7837 #3455\n",
    "index3 = train[pd.isnull(train.family_size) & (train.redemption_status == 0) & (train.test_cust == 1) & (train.test_coup == 1)].sample(3366, random_state=1996).index\n",
    "\n",
    "#(len(train[pd.notnull(train.family_size) & (train.redemption_status == 0)]) / len(train)) * 7837 #4309\n",
    "index4 = train[pd.notnull(train.family_size) & (train.redemption_status == 0) & (train.test_cust == 1) & (train.test_coup == 1)].sample(4309, random_state=1996).index\n",
    "\n",
    "\n",
    "\n",
    "#new train and val set\n",
    "val_index = []\n",
    "for i in [index1,index2, index3, index4]:\n",
    "    val_index.extend(i)#main val_index\n",
    "    \n",
    "train_index = set(train.index)\n",
    "train_index = train_index.symmetric_difference(val_index)#main train index\n",
    "\n",
    "new_train = train.loc[train_index]\n",
    "val = train.loc[val_index].sample(frac=1, random_state = 1996)\n",
    "new_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final_train = new_train.dropna(axis=1).drop(['test_cust','test_coup'], axis=1)\n",
    "#final_test = new_test.dropna(axis=1)#.drop(['coup_redeem'], axis=1)\n",
    "#val = val.dropna(axis=1).drop(['test_cust','test_coup'], axis=1)\n",
    "\n",
    "final_train = train.dropna(axis=1).drop(['test_cust','test_coup'], axis=1)\n",
    "final_test = test.dropna(axis=1)\n",
    "\n",
    "################# Label Encoding\n",
    "\n",
    "#label encoding features\n",
    "final_train['campaign_type'] = final_train.campaign_type.map({'X':0,'Y':1})\n",
    "#val['campaign_type'] = val.campaign_type.map({'X':0,'Y':1})\n",
    "final_test['campaign_type'] = final_test.campaign_type.map({'X':0,'Y':1})\n",
    "\n",
    "final_train['age_range'] = final_train.age_range.map({'46-55':0,'36-45':1,'18-25':2,'26-35':3,'56-70':4,'70+':5})\n",
    "#val['age_range'] = val.age_range.map({'46-55':0,'36-45':1,'18-25':2,'26-35':3,'56-70':4,'70+':5})\n",
    "final_test['age_range'] = final_test.age_range.map({'46-55':0,'36-45':1,'18-25':2,'26-35':3,'56-70':4,'70+':5})\n",
    "\n",
    "###############\n",
    "\n",
    "############## train_test\n",
    "\n",
    "#preparing data\n",
    "X_train = final_train.drop(['redemption_status'],axis=1)\n",
    "y_train = final_train.redemption_status\n",
    "\n",
    "#val_x = val.drop(['redemption_status'],axis=1)\n",
    "#val_y = val.redemption_status\n",
    "\n",
    "X_test = final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "preds1= pd.DataFrame()\n",
    "auc_roc1 = []\n",
    "val_auc = []\n",
    "\n",
    "for k in range(0,10):\n",
    "    df_1 = final_train[final_train.redemption_status == 1]\n",
    "    df_0 = final_train[final_train.redemption_status == 0].sample(1000, random_state =2*k*k*k)\n",
    "    \n",
    "    df = pd.concat([df_0,df_1],axis=0).sample(frac=1)\n",
    "\n",
    "    X_train = df.drop('redemption_status',axis=1)\n",
    "    y_train = df.redemption_status\n",
    "\n",
    "    model1 = XGBClassifier(n_estimators=100, scale_pos_weight=2)\n",
    "    model1.fit(X_train,y_train)\n",
    "\n",
    "    #pred by model1\n",
    "    auc_roc1.append(roc_auc_score(y_train, model1.predict_proba(X_train)[:,1].round(3)))\n",
    "    preds1['k'+str(k)] = model1.predict_proba(X_test)[:,1].round(3)\n",
    "    \n",
    "\n",
    "\n",
    "    print(k, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729695238945161"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = preds1.mean(axis=1)\n",
    "roc_auc_score(val_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = preds1.mean(axis=1)\n",
    "\n",
    "sample['redemption_status'] = pred_test\n",
    "\n",
    "name = 'sol/bestCols_brandbot_2kkk_brand.csv'\n",
    "sample.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "531.667px",
    "left": "820px",
    "right": "20px",
    "top": "105px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
